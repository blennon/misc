<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
<head>
  <title>Chapter 40: Adaptation (Growth)</title>
  <link rel="stylesheet" type="text/css" href="../styles.css"/>
</head>
<body>
  <span class="chapter-number">Chapter Forty</span>
  <h1>Adaptation</h1>
  <p class="first"><em>Goodhart's law and friends</em></p>

  <p class="spiral-note">Spiral return: Adaptation first appeared in Chapter 15. Now we deepen it for systems design.</p>

  <hr/>

  <p class="first">We've seen adaptation as a pattern: systems respond to pressure. Now let's see it as a design consideration. How do you design systems knowing that they—and the people in them—will adapt to whatever you create?</p>

  <h2>Goodhart's Law Revisited</h2>

  <p class="first">"When a measure becomes a target, it ceases to be a good measure."</p>

  <p>We met this before. Now let's go deeper. Why does this happen?</p>

  <p>Before the measure was a target, it tracked something real. It was correlated with what you actually cared about. But once it became a target, people optimized for the measure itself. They found ways to raise the measure without raising the underlying thing. The correlation broke.</p>

  <p>Test scores tracked learning—until they became the target. Then teaching-to-the-test raised scores without necessarily raising learning.</p>

  <p>Crime statistics tracked safety—until they became police performance targets. Then reclassifying crimes raised the statistics without raising safety.</p>

  <p>The general lesson: measuring something changes it. Targeting something changes it more. The system adapts to your intervention.</p>

  <h2>Campbell's Law</h2>

  <p class="first">Related: "The more any quantitative social indicator is used for social decision-making, the more subject it will be to corruption pressures and the more apt it will be to distort and corrupt the social processes it is intended to monitor."</p>

  <p>This is Campbell's Law, and it's Goodhart's cousin. High-stakes metrics get gamed. The more consequential the measurement, the more pressure to manipulate it.</p>

  <p>This isn't necessarily conscious cheating. Often it's people finding clever ways to optimize what's measured, believing they're doing the right thing. The system adapts, and the measure detaches from reality.</p>

  <h2>Designing for Adaptation</h2>

  <p class="first">So how do you design knowing that adaptation will happen?</p>

  <p><strong>Use multiple measures.</strong> A single metric can be gamed. Multiple metrics that triangulate on your actual goal are harder to game while missing the point.</p>

  <p><strong>Measure outcomes, not inputs.</strong> When you measure the process, people optimize the process. When you measure the outcome, they have more freedom to find good processes—and less ability to game the metric without producing the outcome.</p>

  <p><strong>Expect gaming and monitor for it.</strong> Gaming isn't a surprise; it's the default. Build monitoring into the system. When gaming appears, adjust.</p>

  <p><strong>Rotate metrics.</strong> If you change what's measured periodically, gaming strategies don't have time to become entrenched.</p>

  <p><strong>Build in judgment.</strong> Not everything can be measured. Sometimes human judgment needs to complement metrics. Create space for judgment to override metrics when they've become pathological.</p>

  <h2>Adaptive Systems</h2>

  <p class="first">The flip side: sometimes you want systems that adapt. Adaptive systems are resilient—they respond to change rather than breaking.</p>

  <p>Building adaptive capacity means:</p>

  <p><strong>Variety:</strong> Multiple approaches, diverse perspectives, different strategies. If one fails, others might work.</p>

  <p><strong>Feedback:</strong> Fast, accurate information about what's working. Without feedback, adaptation is blind.</p>

  <p><strong>Flexibility:</strong> The ability to change. Rigid systems can't adapt. Build in slack, preserve options, avoid lock-in.</p>

  <p><strong>Learning:</strong> Mechanisms for capturing and spreading lessons. What the system learns should become available to all parts of the system.</p>

  <p>A well-designed system adapts to its environment rather than breaking when the environment changes. This is antifragility—getting stronger from stress rather than weaker.</p>

  <h2>Selection Meets Adaptation</h2>

  <p class="first">Adaptation is selection operating in real time.</p>

  <p>Variants are generated (through individual choices, experiments, randomness). Selection pressure operates (rewards and punishments, success and failure). What works is retained and spread. The system evolves.</p>

  <p>This means you can shape adaptation by shaping selection. Create environments where good adaptations are rewarded and bad ones are punished. Let selection do the work of producing good outcomes.</p>

  <h2>The Deeper Seed</h2>

  <p class="first">Adaptation is now a design consideration. Any system you create will be adapted to. Goodhart's Law and Campbell's Law warn that measures become targets and targets become corrupted.</p>

  <p>The prepared mind designs for adaptation. It uses multiple measures, expects gaming, monitors for drift. It also builds adaptive capacity—variety, feedback, flexibility, learning—so that the system can respond well to change.</p>

  <p>Adaptation isn't your enemy. It's a force you can work with. Design for it.</p>
</body>
</html>