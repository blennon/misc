<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
<head>
  <title>Chapter 18: Probability</title>
  <link rel="stylesheet" type="text/css" href="../styles.css"/>
</head>
<body>
  <span class="chapter-number">Chapter Eighteen</span>
  <h1>Probability</h1>
  <p class="first"><em>Degrees of confidence</em></p>

  <hr/>

  <p class="first">You're not certain it will rain tomorrow, but you think it's more likely than not. You're not sure the project will succeed, but you'd give it decent odds. You believe your friend is honest, but you recognize you could be wrong.</p>

  <p>Most beliefs aren't black or white—they're degrees of confidence. Probability is the language for expressing and reasoning about these degrees. Getting good at it means getting good at being appropriately uncertain.</p>

  <h2>Beliefs as Probabilities</h2>

  <p class="first">Think of a belief not as "yes or no" but as a number between 0 and 1. Zero means certain it's false. One means certain it's true. Everything in between is a degree of credence.</p>

  <p>If you're 70% confident it will rain, that means something like: if you made this kind of judgment many times, you'd expect to be right about 70% of the time. It's a calibrated expression of uncertainty.</p>

  <p>This framing changes how you think about beliefs. Instead of asking "Is it true?" you ask "How confident should I be?" Instead of defending a position, you're tracking your uncertainty. Instead of "I believe X," you think "I'm at 85% on X."</p>

  <p>Not every belief needs a precise number. But thinking in terms of probabilities makes your uncertainty visible rather than hidden.</p>

  <h2>Base Rates</h2>

  <p class="first">Here's one of the most important concepts in probabilistic thinking: the base rate.</p>

  <p>The base rate is how common something is before you have any specific information about the case at hand. If 1% of emails are spam, the base rate for spam is 1%. If 0.1% of the population has a certain disease, the base rate for the disease is 0.1%.</p>

  <p>Base rates matter enormously for inference. If a test for a rare disease has a 95% accuracy rate, a positive result might still mean you probably don't have the disease—because false positives from the 99.9% of healthy people can outnumber true positives from the 0.1% who are sick.</p>

  <p>People consistently neglect base rates. They judge based on how well something fits a category (this person seems like a librarian) without asking how common that category is (there aren't many librarians). This is called the base rate fallacy, and it leads to systematically wrong judgments.</p>

  <p>When you're estimating the probability of something, always ask: what's the base rate? How common is this in general, before I consider the specific evidence?</p>

  <h2>Updating</h2>

  <p class="first">When new evidence arrives, your probability should update. But how much?</p>

  <p>The answer depends on how surprising the evidence would be under different scenarios. If the evidence is what you'd expect if your belief is true, but surprising if your belief is false, then your belief should strengthen a lot. If the evidence is roughly equally likely either way, it shouldn't move you much.</p>

  <p>This is the core of Bayesian reasoning: beliefs update based on the likelihood ratio—how much more or less likely the evidence is under one hypothesis versus another.</p>

  <p>You don't need to do formal calculations. The intuition is enough: surprising evidence moves you more. Evidence that could easily occur regardless of the truth moves you less. And you update from where you started (including the base rate), not from scratch.</p>

  <h2>Calibration</h2>

  <p class="first">A well-calibrated person is one whose expressed confidences match reality.</p>

  <p>If you say "I'm 90% confident" about many things, and you're right about 90% of them, you're well-calibrated. If you're only right about 60% of the things you're 90% confident about, you're overconfident. If you're right about 99% of them, you're underconfident.</p>

  <p>Most people are overconfident. They're too certain about too many things. Their 90% confidences come true 75% of the time. Their "certainties" occasionally prove wrong.</p>

  <p>Calibration is trainable. The practice is simple: make predictions with explicit confidence levels, track the results, notice where you're miscalibrated, adjust. Over time, your gut sense of probability becomes more accurate.</p>

  <p>Well-calibrated uncertainty isn't a sign of weakness—it's a sign of accurate self-knowledge. Saying "I'm 60% confident" when you're genuinely uncertain is more honest and more useful than pretending to certainty you don't have.</p>

  <h2>Expected Value</h2>

  <p class="first">When you're deciding between options under uncertainty, probability combines with outcomes to produce expected value.</p>

  <p>Expected value is probability times payoff, summed across all outcomes. If there's a 50% chance of winning $100 and a 50% chance of winning nothing, the expected value is $50. If there's a 10% chance of winning $1000 and a 90% chance of winning nothing, the expected value is also $100.</p>

  <p>Expected value helps compare options. A lower probability of a bigger payoff might beat a higher probability of a smaller payoff—or vice versa. By multiplying them out, you can compare apples to oranges.</p>

  <p>This isn't the only thing that matters. Risk tolerance, variance, and non-monetary factors all matter too. But expected value is a crucial input to decision-making under uncertainty.</p>

  <h2>Living with Probability</h2>

  <p class="first">Thinking probabilistically changes how you engage with the world.</p>

  <p>You become comfortable with uncertainty. Not everything needs to be resolved into certainty. "I don't know, but I think it's about 70%" is a legitimate and often more honest answer than a fake-confident "yes."</p>

  <p>You separate your confidence from the outcome. A good decision can have a bad outcome if you were unlucky. A bad decision can have a good outcome if you were lucky. Judging decisions by outcomes conflates skill with luck. Probability lets you assess the decision separately.</p>

  <p>You make better predictions. By thinking about base rates, updating on evidence, and calibrating your confidence, your expectations align better with reality. You're less surprised when the probable happens and appropriately surprised when the improbable does.</p>

  <h2>The Seed</h2>

  <p class="first">Probability is the language of uncertainty. Beliefs come in degrees. Base rates set the starting point. Evidence updates the probability. Calibration ensures your confidence matches reality. Expected value helps you decide.</p>

  <p>We'll return to probability in Part IV, when we discuss decisions under uncertainty. For now: notice your uncertainty. Give it a shape. Be appropriately confident and appropriately humble. The world is probabilistic; thinking well means thinking probabilistically.</p>
</body>
</html>